{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project - COMP/ELEC 576\n",
        "\n",
        "Dongwook Kim and Fuad Hasan"
      ],
      "metadata": {
        "id": "BKEhXbqk-eCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-io\n",
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "KENPRGtjJ8kQ",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597817ed-6727-4c45-ce15-b0a6a0f195d9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-io\n",
            "  Downloading tensorflow_io-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.37.1 (from tensorflow-io)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Downloading tensorflow_io-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
            "Successfully installed tensorflow-io-0.37.1 tensorflow-io-gcs-filesystem-0.37.1\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.12/dist-packages (1.4.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.11.12)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.1.1.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dk9msEsXX8ti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202ce450-3d0f-439f-b965-ab6cad7217e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Packages\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)"
      ],
      "metadata": {
        "id": "sJ-1be4_ndBz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make temp folder in local\n",
        "!mkdir -p /content/temp\n",
        "\n",
        "ZIP_PATH = \"/content/drive/MyDrive/Assignments/COMP_Project/data.zip\"\n",
        "!cp \"$ZIP_PATH\" /content/temp/\n",
        "\n",
        "\n",
        "!ls -lh /content/temp"
      ],
      "metadata": {
        "id": "EQO3p8CFELEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58f9ec1-3323-49d2-da7a-9f64dc3e5c47"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 7.5G\n",
            "-rw------- 1 root root 7.5G Dec  9 07:10 data.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Unzip\n",
        "!unzip -q /content/temp/data.zip -d /content/temp/"
      ],
      "metadata": {
        "id": "0d1KKIzmEiHY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "BATCH_SIZE = 32         # 32, 64\n",
        "DROPOUT_RATE = 0.3      # 0.3, 0.5\n",
        "WEIGHT_DECAY = 0.05\n",
        "EPOCHS = 10             # 50\n",
        "LEARNING_RATE = 0.001\n",
        "N_BLOCKS = 4"
      ],
      "metadata": {
        "id": "G0wP9q7wcsjl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nUMjx587X74I"
      },
      "outputs": [],
      "source": [
        "# 1. Load Data\n",
        "local_root = \"/content/temp/\"\n",
        "metadata_dir = \"/content/temp/Sentinel1_metadata.csv\"\n",
        "input_dir = os.path.join(local_root, \"data/S1\")\n",
        "target_dir = os.path.join(local_root, \"data/Floodmaps\")\n",
        "model_prediction_result = \"/content/drive/MyDrive/Assignments/COMP_Project/model_result\"\n",
        "\n",
        "input_files = sorted(glob(os.path.join(input_dir, \"*.tif\")))\n",
        "target_files = sorted(glob(os.path.join(target_dir, \"*.tif\")))\n",
        "\n",
        "input_dict = {os.path.basename(f): f for f in input_files}\n",
        "target_dict = {os.path.basename(f): f for f in target_files}\n",
        "\n",
        "all_files = sorted(set(input_dict.keys()) | set(target_dict.keys()))\n",
        "\n",
        "df = pd.DataFrame({\"filename\": all_files,\n",
        "                   \"input_path\": [input_dict.get(f, None) for f in all_files],\n",
        "                   \"target_path\": [target_dict.get(f, None) for f in all_files]\n",
        "                  })\n",
        "\n",
        "df[\"status\"] = df.apply(lambda row:\n",
        "                        \"matched\" if row[\"input_path\"] is not None and row[\"target_path\"] is not None\n",
        "                        else (\"missing_input\" if row[\"input_path\"] is None else \"missing_target\"), axis=1\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Train/Valid/Test Split\n",
        "df_matched = df[df[\"status\"] == \"matched\"].reset_index(drop=True)\n",
        "\n",
        "train_df, temp_df = train_test_split(df_matched, test_size=0.2, random_state=42)\n",
        "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
        "\n",
        "train_df[\"split\"] = \"train\"\n",
        "valid_df[\"split\"] = \"valid\"\n",
        "test_df[\"split\"] = \"test\"\n",
        "\n",
        "df_split = pd.concat([train_df, valid_df, test_df]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "uw9CSFXuSX_B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Dataset\n",
        "TOLERANCE = 1e-6\n",
        "CLIP_MIN = -30.0\n",
        "CLIP_MAX = 10.0\n",
        "RANGE_MAX_MIN = CLIP_MAX - CLIP_MIN\n",
        "\n",
        "class Sturm_Dataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_path = self.df.loc[idx, \"input_path\"]\n",
        "        target_path = self.df.loc[idx, \"target_path\"]\n",
        "\n",
        "        # --- 1. Input Image (SAR) Processing ---\n",
        "        with rasterio.open(input_path) as src:\n",
        "            # Read input image (already in dB scale)\n",
        "            img = src.read().astype(np.float32)\n",
        "\n",
        "        # SAR valid: Check for non-finite values (NaN/Inf)\n",
        "        sar_valid = np.isfinite(img).all(axis=0)\n",
        "\n",
        "        # --- 2. Target Mask Processing ---\n",
        "        with rasterio.open(target_path) as src:\n",
        "            mask_raw = src.read(1).astype(np.float32)\n",
        "            nod = src.nodata\n",
        "\n",
        "        # Label valid: Robustly check for NoData using a tolerance\n",
        "        if nod is None:\n",
        "            label_valid = np.ones_like(mask_raw, dtype=bool)\n",
        "        else:\n",
        "            label_valid = np.abs(mask_raw - nod) > TOLERANCE\n",
        "\n",
        "        # Convert mask to 0/1 (Flood/No Flood)\n",
        "        mask = (mask_raw > 0).astype(np.float32)\n",
        "\n",
        "        # valid if both sar + label are valid\n",
        "        valid_mask = sar_valid & label_valid\n",
        "\n",
        "        valid_mask_tensor = np.expand_dims(valid_mask, axis=0)\n",
        "        mask_tensor = np.expand_dims(mask, axis=0)\n",
        "\n",
        "        return (\n",
        "            torch.tensor(img, dtype=torch.float32),\n",
        "            torch.tensor(mask_tensor, dtype=torch.float32),\n",
        "            torch.tensor(valid_mask_tensor, dtype=torch.float32),\n",
        "        )"
      ],
      "metadata": {
        "id": "0X-eJhNgnGVc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Sturm_Dataset(df_split[df_split[\"split\"] == \"train\"])\n",
        "valid_dataset = Sturm_Dataset(df_split[df_split[\"split\"] == \"valid\"])\n",
        "test_dataset  = Sturm_Dataset(df_split[df_split[\"split\"] == \"test\"])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True, generator=torch.Generator().manual_seed(42))\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True)"
      ],
      "metadata": {
        "id": "NpqhPyH_VKkK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the first batch\n",
        "# for imgs, masks, valids in train_loader:\n",
        "for imgs, masks, valids in train_loader:\n",
        "    print(f\"Input batch shape: {imgs.shape}\")\n",
        "    print(f\"Mask batch shape: {masks.shape}\")\n",
        "    print(f\"Input min/max: {imgs.min().item():.4f}/{imgs.max().item():.4f}\")\n",
        "    print(f\"Mask unique values: {masks.unique()}\")\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX18zgwHVc4R",
        "outputId": "8006e282-c458-4fe0-a236-67a940731ffd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch shape: torch.Size([32, 2, 128, 128])\n",
            "Mask batch shape: torch.Size([32, 1, 128, 128])\n",
            "Input min/max: -0.4722/1.2913\n",
            "Mask unique values: tensor([0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Models\n",
        "# 4.1 FCN-8\n",
        "class FCN8(nn.Module):\n",
        "    def __init__(self, in_ch=2, num_classes=1, dropout_rate=0.5):\n",
        "        super(FCN8, self).__init__()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, 3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, 3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, 3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, 3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.score_pool3 = nn.Conv2d(256, num_classes, 1)\n",
        "        self.score_pool4 = nn.Conv2d(512, num_classes, 1)\n",
        "        self.score_pool5 = nn.Conv2d(512, num_classes, 1)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        p1 = self.pool(x1)\n",
        "\n",
        "        x2 = self.conv2(p1)\n",
        "        p2 = self.pool(x2)\n",
        "\n",
        "        x3 = self.conv3(p2)\n",
        "        p3 = self.pool(x3)\n",
        "\n",
        "        x4 = self.conv4(p3)\n",
        "        p4 = self.pool(x4)\n",
        "\n",
        "        x5 = self.conv5(p4)\n",
        "        p5 = self.pool(x5)\n",
        "\n",
        "        score5 = self.score_pool5(p5)\n",
        "        score5_up = F.interpolate(score5, size=p4.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        score4 = self.score_pool4(p4)\n",
        "        score4_comb = score5_up + score4\n",
        "        score4_up = F.interpolate(score4_comb, size=p3.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        score3 = self.score_pool3(p3)\n",
        "        score3_comb = score4_up + score3\n",
        "\n",
        "        out = F.interpolate(score3_comb, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "ohfwGiUbnjkQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2 U-Net\n",
        "def double_conv(in_channels, out_channels, dropout_rate=0.0):\n",
        "    layers = [\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "        # nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "        # nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "    ]\n",
        "    if dropout_rate > 0:\n",
        "        layers.append(nn.Dropout2d(dropout_rate))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, n_blocks=4, n_filters_start=64, filter_growth=2, dropout_rate=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dconv_down1 = double_conv(in_ch, 64, dropout_rate)\n",
        "        self.dconv_down2 = double_conv(64, 128, dropout_rate)\n",
        "        self.dconv_down3 = double_conv(128, 256, dropout_rate)\n",
        "        self.dconv_down4 = double_conv(256, 512, dropout_rate)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.dconv_up3 = double_conv(256 + 512, 256, dropout_rate)\n",
        "        self.dconv_up2 = double_conv(128 + 256, 128, dropout_rate)\n",
        "        self.dconv_up1 = double_conv(128 + 64, 64, dropout_rate)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(64, out_ch, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "\n",
        "        conv3 = self.dconv_down3(x)\n",
        "        x = self.maxpool(conv3)\n",
        "\n",
        "        x = self.dconv_down4(x)\n",
        "\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "\n",
        "        x = self.dconv_up3(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv2], dim=1)\n",
        "\n",
        "        x = self.dconv_up2(x)\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, conv1], dim=1)\n",
        "\n",
        "        x = self.dconv_up1(x)\n",
        "\n",
        "        out = self.conv_last(x)\n",
        "        # probs = torch.sigmoid(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "k-fiDAZuW-KQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3 U-Net++\n",
        "class UNetPP(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_ch,\n",
        "        out_ch,\n",
        "        n_blocks=4,\n",
        "        filters=None,\n",
        "        dropout_rate=0.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        if filters is None:\n",
        "            filters = [64 * (2 ** i) for i in range(n_blocks)]\n",
        "        assert len(filters) == n_blocks, \"filters length must match n_blocks\"\n",
        "\n",
        "        self.conv00 = double_conv(in_ch,      filters[0], dropout_rate)\n",
        "        self.conv10 = double_conv(filters[0], filters[1], dropout_rate)\n",
        "        self.conv20 = double_conv(filters[1], filters[2], dropout_rate)\n",
        "        self.conv30 = double_conv(filters[2], filters[3], dropout_rate)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.conv01 = double_conv(filters[0] + filters[1], filters[0], dropout_rate)\n",
        "        self.conv11 = double_conv(filters[1] + filters[2], filters[1], dropout_rate)\n",
        "        self.conv21 = double_conv(filters[2] + filters[3], filters[2], dropout_rate)\n",
        "\n",
        "        self.conv02 = double_conv(filters[0]*2 + filters[1], filters[0], dropout_rate)\n",
        "        self.conv12 = double_conv(filters[1]*2 + filters[2], filters[1], dropout_rate)\n",
        "\n",
        "        self.conv03 = double_conv(filters[0]*3 + filters[1], filters[0], dropout_rate)\n",
        "\n",
        "        self.final = nn.Conv2d(filters[0], out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x00 = self.conv00(x)\n",
        "        x10 = self.conv10(self.pool(x00))\n",
        "        x20 = self.conv20(self.pool(x10))\n",
        "        x30 = self.conv30(self.pool(x20))\n",
        "\n",
        "        x01 = self.conv01(torch.cat([x00, self.up(x10)], dim=1))\n",
        "        x11 = self.conv11(torch.cat([x10, self.up(x20)], dim=1))\n",
        "        x21 = self.conv21(torch.cat([x20, self.up(x30)], dim=1))\n",
        "\n",
        "        x02 = self.conv02(torch.cat([x00, x01, self.up(x11)], dim=1))\n",
        "        x12 = self.conv12(torch.cat([x10, x11, self.up(x21)], dim=1))\n",
        "\n",
        "        x03 = self.conv03(torch.cat([x00, x01, x02, self.up(x12)], dim=1))\n",
        "\n",
        "        return self.final(x03)"
      ],
      "metadata": {
        "id": "wSaPHk2yeayK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model\n",
        "model = UNet(\n",
        "    in_ch=2,\n",
        "    out_ch=1,\n",
        "    n_blocks=N_BLOCKS,\n",
        "    dropout_rate=DROPOUT_RATE\n",
        ").to(DEVICE)"
      ],
      "metadata": {
        "id": "2ufNGuOWiFVj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "pos_weight = torch.tensor([2.4]).to(DEVICE) # pos_weight = 0.706 / 0.294\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='none')\n",
        "\n",
        "\n",
        "# class DiceLoss(nn.Module):\n",
        "#     def __init__(self, smooth=1.0, reduction='mean'):\n",
        "#         super(DiceLoss, self).__init__()\n",
        "#         self.smooth = smooth\n",
        "#         self.reduction = reduction\n",
        "\n",
        "#     def forward(self, inputs, targets):\n",
        "#         inputs = torch.sigmoid(inputs)\n",
        "\n",
        "#         inputs = inputs.view(-1)\n",
        "#         targets = targets.view(-1)\n",
        "\n",
        "#         intersection = (inputs * targets).sum()\n",
        "#         dice_score = (2.0 * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
        "#         dice_loss = 1.0 - dice_score\n",
        "\n",
        "#         if self.reduction == 'mean':\n",
        "#             return dice_loss\n",
        "#         elif self.reduction == 'sum':\n",
        "#             return dice_loss * inputs.numel()\n",
        "#         else:\n",
        "#             return dice_loss\n",
        "\n",
        "# criterion = DiceLoss(smooth=1.0, reduction='mean').to(DEVICE)"
      ],
      "metadata": {
        "id": "eR2ow9LOW-Mu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. EarlyStopping:\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, min_delta=1e-4, verbose=True):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            return False\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter}/{self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                return True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "M73aXMNiI3FV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Save model\n",
        "def get_model_name(model_name, batch_size, dropout, epochs):\n",
        "    D = int(dropout * 10) if dropout < 1 else int(dropout)\n",
        "    return f\"{model_name}_B{batch_size}D{D}E{epochs}\"\n",
        "\n",
        "model_prediction_result = \"/content/drive/MyDrive/Assignments/COMP_Project/save\"\n",
        "best_model_filename = get_model_name(\"U-Net\", BATCH_SIZE, DROPOUT_RATE, EPOCHS) + \".pth\"\n",
        "full_path = os.path.join(model_prediction_result, best_model_filename)"
      ],
      "metadata": {
        "id": "rCw2KxJjJ5Co"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Run the model\n",
        "early_stopper = EarlyStopping(patience=3, min_delta=1e-4)  # Patience = 10\n",
        "best_val_loss = float('inf')\n",
        "log_interval = 10\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for batch_idx, (imgs, masks, valid_mask) in enumerate(train_loader):\n",
        "        imgs, masks, valid_mask = imgs.to(DEVICE), masks.to(DEVICE), valid_mask.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "\n",
        "        loss_tensor = criterion(outputs, masks.float())\n",
        "        loss = (loss_tensor * valid_mask.float()).sum() / (valid_mask.sum() + 1e-8)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(f\"Epoch {epoch+1} | Batch {batch_idx}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks, valid_mask in valid_loader:\n",
        "            imgs, masks, valid_mask = imgs.to(DEVICE), masks.to(DEVICE), valid_mask.to(DEVICE)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            loss_tensor = criterion(outputs, masks.float())\n",
        "            loss = (loss_tensor * valid_mask.float()).sum() / (valid_mask.sum() + 1e-8)\n",
        "            val_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "    val_loss /= len(valid_loader.dataset)\n",
        "    val_losses.append(val_loss)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), full_path)\n",
        "        print(f\"** Best model saved: {full_path} **\")\n",
        "\n",
        "    if early_stopper(val_loss):\n",
        "        print(\"Early stopping triggered!\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6fGnFLRtSSe",
        "outputId": "a4b11868-fad2-4255-ec01-999c1cc6c0e2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Batch 0/541 | Loss: 0.8790\n",
            "Epoch 1 | Batch 10/541 | Loss: 1.0357\n",
            "Epoch 1 | Batch 20/541 | Loss: 0.8951\n",
            "Epoch 1 | Batch 30/541 | Loss: 0.7446\n",
            "Epoch 1 | Batch 40/541 | Loss: 0.8222\n",
            "Epoch 1 | Batch 50/541 | Loss: 0.7661\n",
            "Epoch 1 | Batch 60/541 | Loss: 0.7808\n",
            "Epoch 1 | Batch 70/541 | Loss: 0.8543\n",
            "Epoch 1 | Batch 80/541 | Loss: 0.7433\n",
            "Epoch 1 | Batch 90/541 | Loss: 0.6782\n",
            "Epoch 1 | Batch 100/541 | Loss: 0.6556\n",
            "Epoch 1 | Batch 110/541 | Loss: 0.6312\n",
            "Epoch 1 | Batch 120/541 | Loss: 0.8395\n",
            "Epoch 1 | Batch 130/541 | Loss: 0.8024\n",
            "Epoch 1 | Batch 140/541 | Loss: 0.8306\n",
            "Epoch 1 | Batch 150/541 | Loss: 0.7361\n",
            "Epoch 1 | Batch 160/541 | Loss: 0.6949\n",
            "Epoch 1 | Batch 170/541 | Loss: 0.6884\n",
            "Epoch 1 | Batch 180/541 | Loss: 0.8241\n",
            "Epoch 1 | Batch 190/541 | Loss: 0.8693\n",
            "Epoch 1 | Batch 200/541 | Loss: 0.7512\n",
            "Epoch 1 | Batch 210/541 | Loss: 1.0343\n",
            "Epoch 1 | Batch 220/541 | Loss: 0.7789\n",
            "Epoch 1 | Batch 230/541 | Loss: 0.6874\n",
            "Epoch 1 | Batch 240/541 | Loss: 0.6495\n",
            "Epoch 1 | Batch 250/541 | Loss: 0.7713\n",
            "Epoch 1 | Batch 260/541 | Loss: 0.7699\n",
            "Epoch 1 | Batch 270/541 | Loss: 0.7698\n",
            "Epoch 1 | Batch 280/541 | Loss: 0.6525\n",
            "Epoch 1 | Batch 290/541 | Loss: 0.7421\n",
            "Epoch 1 | Batch 300/541 | Loss: 0.7498\n",
            "Epoch 1 | Batch 310/541 | Loss: 0.6985\n",
            "Epoch 1 | Batch 320/541 | Loss: 0.7013\n",
            "Epoch 1 | Batch 330/541 | Loss: 0.7543\n",
            "Epoch 1 | Batch 340/541 | Loss: 0.9485\n",
            "Epoch 1 | Batch 350/541 | Loss: 0.6702\n",
            "Epoch 1 | Batch 360/541 | Loss: 0.8749\n",
            "Epoch 1 | Batch 370/541 | Loss: 0.9390\n",
            "Epoch 1 | Batch 380/541 | Loss: 0.7688\n",
            "Epoch 1 | Batch 390/541 | Loss: 0.7533\n",
            "Epoch 1 | Batch 400/541 | Loss: 0.7560\n",
            "Epoch 1 | Batch 410/541 | Loss: 0.5952\n",
            "Epoch 1 | Batch 420/541 | Loss: 0.6150\n",
            "Epoch 1 | Batch 430/541 | Loss: 0.6223\n",
            "Epoch 1 | Batch 440/541 | Loss: 1.0199\n",
            "Epoch 1 | Batch 450/541 | Loss: 0.8649\n",
            "Epoch 1 | Batch 460/541 | Loss: 0.9130\n",
            "Epoch 1 | Batch 470/541 | Loss: 0.9912\n",
            "Epoch 1 | Batch 480/541 | Loss: 0.7235\n",
            "Epoch 1 | Batch 490/541 | Loss: 0.7700\n",
            "Epoch 1 | Batch 500/541 | Loss: 0.7597\n",
            "Epoch 1 | Batch 510/541 | Loss: 1.0319\n",
            "Epoch 1 | Batch 520/541 | Loss: 0.7729\n",
            "Epoch 1 | Batch 530/541 | Loss: 0.7719\n",
            "Epoch 1 | Batch 540/541 | Loss: 0.5788\n",
            "Epoch 1: Train Loss=0.7684, Val Loss=0.7471\n",
            "** Best model saved: /content/drive/MyDrive/Assignments/COMP_Project/save/U-Net_B32D3E10.0.pth **\n",
            "Epoch 2 | Batch 0/541 | Loss: 0.7917\n",
            "Epoch 2 | Batch 10/541 | Loss: 0.8016\n",
            "Epoch 2 | Batch 20/541 | Loss: 0.8485\n",
            "Epoch 2 | Batch 30/541 | Loss: 0.7808\n",
            "Epoch 2 | Batch 40/541 | Loss: 0.7829\n",
            "Epoch 2 | Batch 50/541 | Loss: 0.7721\n",
            "Epoch 2 | Batch 60/541 | Loss: 0.7855\n",
            "Epoch 2 | Batch 70/541 | Loss: 0.8454\n",
            "Epoch 2 | Batch 80/541 | Loss: 0.7251\n",
            "Epoch 2 | Batch 90/541 | Loss: 0.6427\n",
            "Epoch 2 | Batch 100/541 | Loss: 0.7179\n",
            "Epoch 2 | Batch 110/541 | Loss: 0.6265\n",
            "Epoch 2 | Batch 120/541 | Loss: 0.8282\n",
            "Epoch 2 | Batch 130/541 | Loss: 0.7707\n",
            "Epoch 2 | Batch 140/541 | Loss: 0.7996\n",
            "Epoch 2 | Batch 150/541 | Loss: 0.7843\n",
            "Epoch 2 | Batch 160/541 | Loss: 0.7313\n",
            "Epoch 2 | Batch 170/541 | Loss: 0.7104\n",
            "Epoch 2 | Batch 180/541 | Loss: 0.8791\n",
            "Epoch 2 | Batch 190/541 | Loss: 0.8723\n",
            "Epoch 2 | Batch 200/541 | Loss: 0.6995\n",
            "Epoch 2 | Batch 210/541 | Loss: 1.0171\n",
            "Epoch 2 | Batch 220/541 | Loss: 0.7392\n",
            "Epoch 2 | Batch 230/541 | Loss: 0.6975\n",
            "Epoch 2 | Batch 240/541 | Loss: 0.6482\n",
            "Epoch 2 | Batch 250/541 | Loss: 0.7630\n",
            "Epoch 2 | Batch 260/541 | Loss: 0.7922\n",
            "Epoch 2 | Batch 270/541 | Loss: 0.7779\n",
            "Epoch 2 | Batch 280/541 | Loss: 0.6454\n",
            "Epoch 2 | Batch 290/541 | Loss: 0.6239\n",
            "Epoch 2 | Batch 300/541 | Loss: 0.7475\n",
            "Epoch 2 | Batch 310/541 | Loss: 0.6664\n",
            "Epoch 2 | Batch 320/541 | Loss: 0.6958\n",
            "Epoch 2 | Batch 330/541 | Loss: 0.7879\n",
            "Epoch 2 | Batch 340/541 | Loss: 0.8954\n",
            "Epoch 2 | Batch 350/541 | Loss: 0.6660\n",
            "Epoch 2 | Batch 360/541 | Loss: 0.8978\n",
            "Epoch 2 | Batch 370/541 | Loss: 0.9284\n",
            "Epoch 2 | Batch 380/541 | Loss: 0.7772\n",
            "Epoch 2 | Batch 390/541 | Loss: 0.7537\n",
            "Epoch 2 | Batch 400/541 | Loss: 0.7443\n",
            "Epoch 2 | Batch 410/541 | Loss: 0.6268\n",
            "Epoch 2 | Batch 420/541 | Loss: 0.6200\n",
            "Epoch 2 | Batch 430/541 | Loss: 0.6228\n",
            "Epoch 2 | Batch 440/541 | Loss: 0.9336\n",
            "Epoch 2 | Batch 450/541 | Loss: 0.8549\n",
            "Epoch 2 | Batch 460/541 | Loss: 0.8599\n",
            "Epoch 2 | Batch 470/541 | Loss: 0.9677\n",
            "Epoch 2 | Batch 480/541 | Loss: 0.6848\n",
            "Epoch 2 | Batch 490/541 | Loss: 0.7720\n",
            "Epoch 2 | Batch 500/541 | Loss: 0.7241\n",
            "Epoch 2 | Batch 510/541 | Loss: 0.9695\n",
            "Epoch 2 | Batch 520/541 | Loss: 0.7443\n",
            "Epoch 2 | Batch 530/541 | Loss: 0.8169\n",
            "Epoch 2 | Batch 540/541 | Loss: 0.5492\n",
            "Epoch 2: Train Loss=0.7522, Val Loss=0.7514\n",
            "EarlyStopping counter: 1/3\n",
            "Epoch 3 | Batch 0/541 | Loss: 0.8104\n",
            "Epoch 3 | Batch 10/541 | Loss: 0.7635\n",
            "Epoch 3 | Batch 20/541 | Loss: 0.8550\n",
            "Epoch 3 | Batch 30/541 | Loss: 0.7178\n",
            "Epoch 3 | Batch 40/541 | Loss: 0.8089\n",
            "Epoch 3 | Batch 50/541 | Loss: 0.7554\n",
            "Epoch 3 | Batch 60/541 | Loss: 0.7752\n",
            "Epoch 3 | Batch 70/541 | Loss: 0.8907\n",
            "Epoch 3 | Batch 80/541 | Loss: 0.7499\n",
            "Epoch 3 | Batch 90/541 | Loss: 0.6488\n",
            "Epoch 3 | Batch 100/541 | Loss: 0.7068\n",
            "Epoch 3 | Batch 110/541 | Loss: 0.6046\n",
            "Epoch 3 | Batch 120/541 | Loss: 0.8187\n",
            "Epoch 3 | Batch 130/541 | Loss: 0.7960\n",
            "Epoch 3 | Batch 140/541 | Loss: 0.8047\n",
            "Epoch 3 | Batch 150/541 | Loss: 0.7409\n",
            "Epoch 3 | Batch 160/541 | Loss: 0.7011\n",
            "Epoch 3 | Batch 170/541 | Loss: 0.6947\n",
            "Epoch 3 | Batch 180/541 | Loss: 0.8296\n",
            "Epoch 3 | Batch 190/541 | Loss: 0.8765\n",
            "Epoch 3 | Batch 200/541 | Loss: 0.7386\n",
            "Epoch 3 | Batch 210/541 | Loss: 0.9953\n",
            "Epoch 3 | Batch 220/541 | Loss: 0.7538\n",
            "Epoch 3 | Batch 230/541 | Loss: 0.7482\n",
            "Epoch 3 | Batch 240/541 | Loss: 0.6504\n",
            "Epoch 3 | Batch 250/541 | Loss: 0.7504\n",
            "Epoch 3 | Batch 260/541 | Loss: 0.7918\n",
            "Epoch 3 | Batch 270/541 | Loss: 0.7259\n",
            "Epoch 3 | Batch 280/541 | Loss: 0.6369\n",
            "Epoch 3 | Batch 290/541 | Loss: 0.6880\n",
            "Epoch 3 | Batch 300/541 | Loss: 0.7340\n",
            "Epoch 3 | Batch 310/541 | Loss: 0.6189\n",
            "Epoch 3 | Batch 320/541 | Loss: 0.6949\n",
            "Epoch 3 | Batch 330/541 | Loss: 0.7809\n",
            "Epoch 3 | Batch 340/541 | Loss: 0.9048\n",
            "Epoch 3 | Batch 350/541 | Loss: 0.6680\n",
            "Epoch 3 | Batch 360/541 | Loss: 0.8782\n",
            "Epoch 3 | Batch 370/541 | Loss: 0.9416\n",
            "Epoch 3 | Batch 380/541 | Loss: 0.7910\n",
            "Epoch 3 | Batch 390/541 | Loss: 0.7404\n",
            "Epoch 3 | Batch 400/541 | Loss: 0.7346\n",
            "Epoch 3 | Batch 410/541 | Loss: 0.6303\n",
            "Epoch 3 | Batch 420/541 | Loss: 0.6233\n",
            "Epoch 3 | Batch 430/541 | Loss: 0.6245\n",
            "Epoch 3 | Batch 440/541 | Loss: 1.0216\n",
            "Epoch 3 | Batch 450/541 | Loss: 0.8291\n",
            "Epoch 3 | Batch 460/541 | Loss: 0.8806\n",
            "Epoch 3 | Batch 470/541 | Loss: 0.9721\n",
            "Epoch 3 | Batch 480/541 | Loss: 0.6916\n",
            "Epoch 3 | Batch 490/541 | Loss: 0.7637\n",
            "Epoch 3 | Batch 500/541 | Loss: 0.7414\n",
            "Epoch 3 | Batch 510/541 | Loss: 0.9636\n",
            "Epoch 3 | Batch 520/541 | Loss: 0.7922\n",
            "Epoch 3 | Batch 530/541 | Loss: 0.7564\n",
            "Epoch 3 | Batch 540/541 | Loss: 0.5490\n",
            "Epoch 3: Train Loss=0.7509, Val Loss=0.7445\n",
            "** Best model saved: /content/drive/MyDrive/Assignments/COMP_Project/save/U-Net_B32D3E10.0.pth **\n",
            "Epoch 4 | Batch 0/541 | Loss: 0.8111\n",
            "Epoch 4 | Batch 10/541 | Loss: 0.7574\n",
            "Epoch 4 | Batch 20/541 | Loss: 0.8611\n",
            "Epoch 4 | Batch 30/541 | Loss: 0.7410\n",
            "Epoch 4 | Batch 40/541 | Loss: 0.8038\n",
            "Epoch 4 | Batch 50/541 | Loss: 0.7557\n",
            "Epoch 4 | Batch 60/541 | Loss: 0.7715\n",
            "Epoch 4 | Batch 70/541 | Loss: 0.8958\n",
            "Epoch 4 | Batch 80/541 | Loss: 0.7532\n",
            "Epoch 4 | Batch 90/541 | Loss: 0.6238\n",
            "Epoch 4 | Batch 100/541 | Loss: 0.6835\n",
            "Epoch 4 | Batch 110/541 | Loss: 0.6382\n",
            "Epoch 4 | Batch 120/541 | Loss: 0.8154\n",
            "Epoch 4 | Batch 130/541 | Loss: 0.7870\n",
            "Epoch 4 | Batch 140/541 | Loss: 0.8309\n",
            "Epoch 4 | Batch 150/541 | Loss: 0.7692\n",
            "Epoch 4 | Batch 160/541 | Loss: 0.7040\n",
            "Epoch 4 | Batch 170/541 | Loss: 0.6899\n",
            "Epoch 4 | Batch 180/541 | Loss: 0.8278\n",
            "Epoch 4 | Batch 190/541 | Loss: 0.9076\n",
            "Epoch 4 | Batch 200/541 | Loss: 0.7557\n",
            "Epoch 4 | Batch 210/541 | Loss: 0.9936\n",
            "Epoch 4 | Batch 220/541 | Loss: 0.7563\n",
            "Epoch 4 | Batch 230/541 | Loss: 0.7108\n",
            "Epoch 4 | Batch 240/541 | Loss: 0.6149\n",
            "Epoch 4 | Batch 250/541 | Loss: 0.7395\n",
            "Epoch 4 | Batch 260/541 | Loss: 0.7364\n",
            "Epoch 4 | Batch 270/541 | Loss: 0.7498\n",
            "Epoch 4 | Batch 280/541 | Loss: 0.6086\n",
            "Epoch 4 | Batch 290/541 | Loss: 0.6796\n",
            "Epoch 4 | Batch 300/541 | Loss: 0.6882\n",
            "Epoch 4 | Batch 310/541 | Loss: 0.6142\n",
            "Epoch 4 | Batch 320/541 | Loss: 0.7223\n",
            "Epoch 4 | Batch 330/541 | Loss: 0.8016\n",
            "Epoch 4 | Batch 340/541 | Loss: 0.9084\n",
            "Epoch 4 | Batch 350/541 | Loss: 0.6680\n",
            "Epoch 4 | Batch 360/541 | Loss: 0.8839\n",
            "Epoch 4 | Batch 370/541 | Loss: 0.9494\n",
            "Epoch 4 | Batch 380/541 | Loss: 0.7426\n",
            "Epoch 4 | Batch 390/541 | Loss: 0.7446\n",
            "Epoch 4 | Batch 400/541 | Loss: 0.7726\n",
            "Epoch 4 | Batch 410/541 | Loss: 0.6088\n",
            "Epoch 4 | Batch 420/541 | Loss: 0.6103\n",
            "Epoch 4 | Batch 430/541 | Loss: 0.6157\n",
            "Epoch 4 | Batch 440/541 | Loss: 0.9955\n",
            "Epoch 4 | Batch 450/541 | Loss: 0.8341\n",
            "Epoch 4 | Batch 460/541 | Loss: 0.8674\n",
            "Epoch 4 | Batch 470/541 | Loss: 0.9431\n",
            "Epoch 4 | Batch 480/541 | Loss: 0.7202\n",
            "Epoch 4 | Batch 490/541 | Loss: 0.7546\n",
            "Epoch 4 | Batch 500/541 | Loss: 0.7276\n",
            "Epoch 4 | Batch 510/541 | Loss: 1.0042\n",
            "Epoch 4 | Batch 520/541 | Loss: 0.7418\n",
            "Epoch 4 | Batch 530/541 | Loss: 0.8155\n",
            "Epoch 4 | Batch 540/541 | Loss: 0.5682\n",
            "Epoch 4: Train Loss=0.7495, Val Loss=0.7437\n",
            "** Best model saved: /content/drive/MyDrive/Assignments/COMP_Project/save/U-Net_B32D3E10.0.pth **\n",
            "Epoch 5 | Batch 0/541 | Loss: 0.7803\n",
            "Epoch 5 | Batch 10/541 | Loss: 0.7905\n",
            "Epoch 5 | Batch 20/541 | Loss: 0.8623\n",
            "Epoch 5 | Batch 30/541 | Loss: 0.7334\n",
            "Epoch 5 | Batch 40/541 | Loss: 0.7962\n",
            "Epoch 5 | Batch 50/541 | Loss: 0.7395\n",
            "Epoch 5 | Batch 60/541 | Loss: 0.8061\n",
            "Epoch 5 | Batch 70/541 | Loss: 0.9062\n",
            "Epoch 5 | Batch 80/541 | Loss: 0.7527\n",
            "Epoch 5 | Batch 90/541 | Loss: 0.6331\n",
            "Epoch 5 | Batch 100/541 | Loss: 0.7030\n",
            "Epoch 5 | Batch 110/541 | Loss: 0.6222\n",
            "Epoch 5 | Batch 120/541 | Loss: 0.8380\n",
            "Epoch 5 | Batch 130/541 | Loss: 0.7946\n",
            "Epoch 5 | Batch 140/541 | Loss: 0.7503\n",
            "Epoch 5 | Batch 150/541 | Loss: 0.7223\n",
            "Epoch 5 | Batch 160/541 | Loss: 0.7051\n",
            "Epoch 5 | Batch 170/541 | Loss: 0.6959\n",
            "Epoch 5 | Batch 180/541 | Loss: 0.8454\n",
            "Epoch 5 | Batch 190/541 | Loss: 0.8378\n",
            "Epoch 5 | Batch 200/541 | Loss: 0.7151\n",
            "Epoch 5 | Batch 210/541 | Loss: 1.0048\n",
            "Epoch 5 | Batch 220/541 | Loss: 0.7468\n",
            "Epoch 5 | Batch 230/541 | Loss: 0.7120\n",
            "Epoch 5 | Batch 240/541 | Loss: 0.6343\n",
            "Epoch 5 | Batch 250/541 | Loss: 0.7272\n",
            "Epoch 5 | Batch 260/541 | Loss: 0.7667\n",
            "Epoch 5 | Batch 270/541 | Loss: 0.7262\n",
            "Epoch 5 | Batch 280/541 | Loss: 0.6320\n",
            "Epoch 5 | Batch 290/541 | Loss: 0.6950\n",
            "Epoch 5 | Batch 300/541 | Loss: 0.7398\n",
            "Epoch 5 | Batch 310/541 | Loss: 0.6664\n",
            "Epoch 5 | Batch 320/541 | Loss: 0.7084\n",
            "Epoch 5 | Batch 330/541 | Loss: 0.7837\n",
            "Epoch 5 | Batch 340/541 | Loss: 0.8969\n",
            "Epoch 5 | Batch 350/541 | Loss: 0.6542\n",
            "Epoch 5 | Batch 360/541 | Loss: 0.8367\n",
            "Epoch 5 | Batch 370/541 | Loss: 1.0016\n",
            "Epoch 5 | Batch 380/541 | Loss: 0.7545\n",
            "Epoch 5 | Batch 390/541 | Loss: 0.7400\n",
            "Epoch 5 | Batch 400/541 | Loss: 0.7473\n",
            "Epoch 5 | Batch 410/541 | Loss: 0.6099\n",
            "Epoch 5 | Batch 420/541 | Loss: 0.6359\n",
            "Epoch 5 | Batch 430/541 | Loss: 0.6279\n",
            "Epoch 5 | Batch 440/541 | Loss: 0.9258\n",
            "Epoch 5 | Batch 450/541 | Loss: 0.8066\n",
            "Epoch 5 | Batch 460/541 | Loss: 0.8778\n",
            "Epoch 5 | Batch 470/541 | Loss: 0.9727\n",
            "Epoch 5 | Batch 480/541 | Loss: 0.7007\n",
            "Epoch 5 | Batch 490/541 | Loss: 0.7593\n",
            "Epoch 5 | Batch 500/541 | Loss: 0.7630\n",
            "Epoch 5 | Batch 510/541 | Loss: 0.9435\n",
            "Epoch 5 | Batch 520/541 | Loss: 0.7433\n",
            "Epoch 5 | Batch 530/541 | Loss: 0.7797\n",
            "Epoch 5 | Batch 540/541 | Loss: 0.5988\n",
            "Epoch 5: Train Loss=0.7475, Val Loss=0.7404\n",
            "** Best model saved: /content/drive/MyDrive/Assignments/COMP_Project/save/U-Net_B32D3E10.0.pth **\n",
            "Epoch 6 | Batch 0/541 | Loss: 0.8192\n",
            "Epoch 6 | Batch 10/541 | Loss: 0.7886\n",
            "Epoch 6 | Batch 20/541 | Loss: 0.8546\n",
            "Epoch 6 | Batch 30/541 | Loss: 0.7176\n",
            "Epoch 6 | Batch 40/541 | Loss: 0.8051\n",
            "Epoch 6 | Batch 50/541 | Loss: 0.7300\n",
            "Epoch 6 | Batch 60/541 | Loss: 0.7324\n",
            "Epoch 6 | Batch 70/541 | Loss: 0.9445\n",
            "Epoch 6 | Batch 80/541 | Loss: 0.7209\n",
            "Epoch 6 | Batch 90/541 | Loss: 0.6634\n",
            "Epoch 6 | Batch 100/541 | Loss: 0.6540\n",
            "Epoch 6 | Batch 110/541 | Loss: 0.5975\n",
            "Epoch 6 | Batch 120/541 | Loss: 0.8178\n",
            "Epoch 6 | Batch 130/541 | Loss: 0.8026\n",
            "Epoch 6 | Batch 140/541 | Loss: 0.7708\n",
            "Epoch 6 | Batch 150/541 | Loss: 0.7013\n",
            "Epoch 6 | Batch 160/541 | Loss: 0.7465\n",
            "Epoch 6 | Batch 170/541 | Loss: 0.6965\n",
            "Epoch 6 | Batch 180/541 | Loss: 0.8810\n",
            "Epoch 6 | Batch 190/541 | Loss: 0.8520\n",
            "Epoch 6 | Batch 200/541 | Loss: 0.7372\n",
            "Epoch 6 | Batch 210/541 | Loss: 1.0566\n",
            "Epoch 6 | Batch 220/541 | Loss: 0.7569\n",
            "Epoch 6 | Batch 230/541 | Loss: 0.7187\n",
            "Epoch 6 | Batch 240/541 | Loss: 0.6462\n",
            "Epoch 6 | Batch 250/541 | Loss: 0.7517\n",
            "Epoch 6 | Batch 260/541 | Loss: 0.7876\n",
            "Epoch 6 | Batch 270/541 | Loss: 0.7799\n",
            "Epoch 6 | Batch 280/541 | Loss: 0.6755\n",
            "Epoch 6 | Batch 290/541 | Loss: 0.7103\n",
            "Epoch 6 | Batch 300/541 | Loss: 0.7589\n",
            "Epoch 6 | Batch 310/541 | Loss: 0.6576\n",
            "Epoch 6 | Batch 320/541 | Loss: 0.6781\n",
            "Epoch 6 | Batch 330/541 | Loss: 0.7863\n",
            "Epoch 6 | Batch 340/541 | Loss: 0.9125\n",
            "Epoch 6 | Batch 350/541 | Loss: 0.6674\n",
            "Epoch 6 | Batch 360/541 | Loss: 0.8679\n",
            "Epoch 6 | Batch 370/541 | Loss: 0.9267\n",
            "Epoch 6 | Batch 380/541 | Loss: 0.7765\n",
            "Epoch 6 | Batch 390/541 | Loss: 0.7414\n",
            "Epoch 6 | Batch 400/541 | Loss: 0.7709\n",
            "Epoch 6 | Batch 410/541 | Loss: 0.6086\n",
            "Epoch 6 | Batch 420/541 | Loss: 0.6291\n",
            "Epoch 6 | Batch 430/541 | Loss: 0.6157\n",
            "Epoch 6 | Batch 440/541 | Loss: 0.9747\n",
            "Epoch 6 | Batch 450/541 | Loss: 0.8576\n",
            "Epoch 6 | Batch 460/541 | Loss: 0.8457\n",
            "Epoch 6 | Batch 470/541 | Loss: 0.9750\n",
            "Epoch 6 | Batch 480/541 | Loss: 0.6983\n",
            "Epoch 6 | Batch 490/541 | Loss: 0.7513\n",
            "Epoch 6 | Batch 500/541 | Loss: 0.7500\n",
            "Epoch 6 | Batch 510/541 | Loss: 0.9782\n",
            "Epoch 6 | Batch 520/541 | Loss: 0.7741\n",
            "Epoch 6 | Batch 530/541 | Loss: 0.8134\n",
            "Epoch 6 | Batch 540/541 | Loss: 0.5984\n",
            "Epoch 6: Train Loss=0.7488, Val Loss=0.7482\n",
            "EarlyStopping counter: 1/3\n",
            "Epoch 7 | Batch 0/541 | Loss: 0.7852\n",
            "Epoch 7 | Batch 10/541 | Loss: 0.7932\n",
            "Epoch 7 | Batch 20/541 | Loss: 0.8325\n",
            "Epoch 7 | Batch 30/541 | Loss: 0.7285\n",
            "Epoch 7 | Batch 40/541 | Loss: 0.8096\n",
            "Epoch 7 | Batch 50/541 | Loss: 0.7699\n",
            "Epoch 7 | Batch 60/541 | Loss: 0.7419\n",
            "Epoch 7 | Batch 70/541 | Loss: 0.8762\n",
            "Epoch 7 | Batch 80/541 | Loss: 0.7266\n",
            "Epoch 7 | Batch 90/541 | Loss: 0.6794\n",
            "Epoch 7 | Batch 100/541 | Loss: 0.6761\n",
            "Epoch 7 | Batch 110/541 | Loss: 0.6092\n",
            "Epoch 7 | Batch 120/541 | Loss: 0.8220\n",
            "Epoch 7 | Batch 130/541 | Loss: 0.8098\n",
            "Epoch 7 | Batch 140/541 | Loss: 0.7529\n",
            "Epoch 7 | Batch 150/541 | Loss: 0.7311\n",
            "Epoch 7 | Batch 160/541 | Loss: 0.6900\n",
            "Epoch 7 | Batch 170/541 | Loss: 0.6862\n",
            "Epoch 7 | Batch 180/541 | Loss: 0.8528\n",
            "Epoch 7 | Batch 190/541 | Loss: 0.8799\n",
            "Epoch 7 | Batch 200/541 | Loss: 0.7464\n",
            "Epoch 7 | Batch 210/541 | Loss: 1.0810\n",
            "Epoch 7 | Batch 220/541 | Loss: 0.7469\n",
            "Epoch 7 | Batch 230/541 | Loss: 0.7401\n",
            "Epoch 7 | Batch 240/541 | Loss: 0.6403\n",
            "Epoch 7 | Batch 250/541 | Loss: 0.7781\n",
            "Epoch 7 | Batch 260/541 | Loss: 0.7831\n",
            "Epoch 7 | Batch 270/541 | Loss: 0.7349\n",
            "Epoch 7 | Batch 280/541 | Loss: 0.6518\n",
            "Epoch 7 | Batch 290/541 | Loss: 0.6759\n",
            "Epoch 7 | Batch 300/541 | Loss: 0.6919\n",
            "Epoch 7 | Batch 310/541 | Loss: 0.6496\n",
            "Epoch 7 | Batch 320/541 | Loss: 0.6844\n",
            "Epoch 7 | Batch 330/541 | Loss: 0.7676\n",
            "Epoch 7 | Batch 340/541 | Loss: 0.8864\n",
            "Epoch 7 | Batch 350/541 | Loss: 0.6621\n",
            "Epoch 7 | Batch 360/541 | Loss: 0.8773\n",
            "Epoch 7 | Batch 370/541 | Loss: 0.9602\n",
            "Epoch 7 | Batch 380/541 | Loss: 0.7492\n",
            "Epoch 7 | Batch 390/541 | Loss: 0.7030\n",
            "Epoch 7 | Batch 400/541 | Loss: 0.7920\n",
            "Epoch 7 | Batch 410/541 | Loss: 0.5999\n",
            "Epoch 7 | Batch 420/541 | Loss: 0.6261\n",
            "Epoch 7 | Batch 430/541 | Loss: 0.6250\n",
            "Epoch 7 | Batch 440/541 | Loss: 0.9818\n",
            "Epoch 7 | Batch 450/541 | Loss: 0.8426\n",
            "Epoch 7 | Batch 460/541 | Loss: 0.8876\n",
            "Epoch 7 | Batch 470/541 | Loss: 0.9544\n",
            "Epoch 7 | Batch 480/541 | Loss: 0.7295\n",
            "Epoch 7 | Batch 490/541 | Loss: 0.7775\n",
            "Epoch 7 | Batch 500/541 | Loss: 0.7382\n",
            "Epoch 7 | Batch 510/541 | Loss: 0.9726\n",
            "Epoch 7 | Batch 520/541 | Loss: 0.6991\n",
            "Epoch 7 | Batch 530/541 | Loss: 0.7860\n",
            "Epoch 7 | Batch 540/541 | Loss: 0.5386\n",
            "Epoch 7: Train Loss=0.7471, Val Loss=0.7407\n",
            "EarlyStopping counter: 2/3\n",
            "Epoch 8 | Batch 0/541 | Loss: 0.7805\n",
            "Epoch 8 | Batch 10/541 | Loss: 0.7662\n",
            "Epoch 8 | Batch 20/541 | Loss: 0.7966\n",
            "Epoch 8 | Batch 30/541 | Loss: 0.6989\n",
            "Epoch 8 | Batch 40/541 | Loss: 0.8260\n",
            "Epoch 8 | Batch 50/541 | Loss: 0.7682\n",
            "Epoch 8 | Batch 60/541 | Loss: 0.7683\n",
            "Epoch 8 | Batch 70/541 | Loss: 0.9571\n",
            "Epoch 8 | Batch 80/541 | Loss: 0.7451\n",
            "Epoch 8 | Batch 90/541 | Loss: 0.6661\n",
            "Epoch 8 | Batch 100/541 | Loss: 0.6473\n",
            "Epoch 8 | Batch 110/541 | Loss: 0.6612\n",
            "Epoch 8 | Batch 120/541 | Loss: 0.8224\n",
            "Epoch 8 | Batch 130/541 | Loss: 0.7919\n",
            "Epoch 8 | Batch 140/541 | Loss: 0.7795\n",
            "Epoch 8 | Batch 150/541 | Loss: 0.7573\n",
            "Epoch 8 | Batch 160/541 | Loss: 0.6769\n",
            "Epoch 8 | Batch 170/541 | Loss: 0.6672\n",
            "Epoch 8 | Batch 180/541 | Loss: 0.8870\n",
            "Epoch 8 | Batch 190/541 | Loss: 0.8710\n",
            "Epoch 8 | Batch 200/541 | Loss: 0.7288\n",
            "Epoch 8 | Batch 210/541 | Loss: 1.0470\n",
            "Epoch 8 | Batch 220/541 | Loss: 0.7246\n",
            "Epoch 8 | Batch 230/541 | Loss: 0.7187\n",
            "Epoch 8 | Batch 240/541 | Loss: 0.6274\n",
            "Epoch 8 | Batch 250/541 | Loss: 0.7412\n",
            "Epoch 8 | Batch 260/541 | Loss: 0.7881\n",
            "Epoch 8 | Batch 270/541 | Loss: 0.7216\n",
            "Epoch 8 | Batch 280/541 | Loss: 0.6488\n",
            "Epoch 8 | Batch 290/541 | Loss: 0.6922\n",
            "Epoch 8 | Batch 300/541 | Loss: 0.7228\n",
            "Epoch 8 | Batch 310/541 | Loss: 0.7199\n",
            "Epoch 8 | Batch 320/541 | Loss: 0.6787\n",
            "Epoch 8 | Batch 330/541 | Loss: 0.7988\n",
            "Epoch 8 | Batch 340/541 | Loss: 0.9147\n",
            "Epoch 8 | Batch 350/541 | Loss: 0.6831\n",
            "Epoch 8 | Batch 360/541 | Loss: 0.8729\n",
            "Epoch 8 | Batch 370/541 | Loss: 0.9324\n",
            "Epoch 8 | Batch 380/541 | Loss: 0.7388\n",
            "Epoch 8 | Batch 390/541 | Loss: 0.7417\n",
            "Epoch 8 | Batch 400/541 | Loss: 0.7268\n",
            "Epoch 8 | Batch 410/541 | Loss: 0.6122\n",
            "Epoch 8 | Batch 420/541 | Loss: 0.6396\n",
            "Epoch 8 | Batch 430/541 | Loss: 0.6356\n",
            "Epoch 8 | Batch 440/541 | Loss: 1.0290\n",
            "Epoch 8 | Batch 450/541 | Loss: 0.8412\n",
            "Epoch 8 | Batch 460/541 | Loss: 0.8590\n",
            "Epoch 8 | Batch 470/541 | Loss: 0.9507\n",
            "Epoch 8 | Batch 480/541 | Loss: 0.7082\n",
            "Epoch 8 | Batch 490/541 | Loss: 0.7946\n",
            "Epoch 8 | Batch 500/541 | Loss: 0.7127\n",
            "Epoch 8 | Batch 510/541 | Loss: 0.9486\n",
            "Epoch 8 | Batch 520/541 | Loss: 0.7286\n",
            "Epoch 8 | Batch 530/541 | Loss: 0.7954\n",
            "Epoch 8 | Batch 540/541 | Loss: 0.5657\n",
            "Epoch 8: Train Loss=0.7464, Val Loss=0.7426\n",
            "EarlyStopping counter: 3/3\n",
            "Early stopping triggered!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Plot loss curve\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train/Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iyHfbrYTKH0A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "ccd4ac13-4a0c-41fd-9b52-4a052fbee3e7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Evaluate the model\n",
        "def evaluate_model_simple(model, data_loader, device, dataset_name=\"Test Set\", threshold=0.5):\n",
        "    model.eval()\n",
        "    total_tp, total_fp, total_fn, total_tn = 0, 0, 0, 0\n",
        "\n",
        "    print(f\"\\n===== Evaluating {dataset_name} =====\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (imgs, masks, valid_mask) in enumerate(data_loader):\n",
        "            imgs = imgs.to(device)\n",
        "            true_mask = masks.to(device).squeeze(1).bool()\n",
        "            valid_mask = valid_mask.to(device).squeeze(1).bool()\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            pred_mask = (torch.sigmoid(outputs) > threshold).squeeze(1)\n",
        "\n",
        "            # Valid pixels\n",
        "            pred_valid = pred_mask[valid_mask]\n",
        "            true_valid = true_mask[valid_mask]\n",
        "\n",
        "            # confusion matrix\n",
        "            tp = (pred_valid & true_valid).sum().item()\n",
        "            tn = (~pred_valid & ~true_valid).sum().item()\n",
        "            fp = (pred_valid & ~true_valid).sum().item()\n",
        "            fn = (~pred_valid & true_valid).sum().item()\n",
        "\n",
        "            total_tp += tp\n",
        "            total_tn += tn\n",
        "            total_fp += fp\n",
        "            total_fn += fn\n",
        "\n",
        "    epsilon = 1e-7\n",
        "\n",
        "    precision = total_tp / (total_tp + total_fp + epsilon)\n",
        "    recall = total_tp / (total_tp + total_fn + epsilon)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + epsilon)\n",
        "    iou = total_tp / (total_tp + total_fp + total_fn + epsilon)\n",
        "    oa = (total_tp + total_tn) / (total_tp + total_tn + total_fp + total_fn + epsilon)\n",
        "    fpr = total_fp / (total_fp + total_tn + epsilon)\n",
        "    mdr = total_fn / (total_tp + total_fn + epsilon)\n",
        "\n",
        "    print(f\"[{dataset_name}] Precision: {precision:.4f}\")\n",
        "    print(f\"[{dataset_name}] Recall:    {recall:.4f}\")\n",
        "    print(f\"[{dataset_name}] F1 Score:  {f1:.4f}\")\n",
        "    print(f\"[{dataset_name}] IoU:       {iou:.4f}\")\n",
        "    print(f\"[{dataset_name}] Accuracy:  {oa:.4f}\")\n",
        "\n",
        "    return f1, iou\n"
      ],
      "metadata": {
        "id": "DicaKKQRFDFr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation\n",
        "evaluate_model_simple(model, valid_loader, DEVICE, dataset_name=\"Validation Set\")\n",
        "\n",
        "# Test\n",
        "evaluate_model_simple(model, test_loader, DEVICE, dataset_name=\"Test Set\")"
      ],
      "metadata": {
        "id": "GpEe1lYqW-Th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f90795-53f3-4638-da96-ea29392cecda"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Evaluating Validation Set =====\n",
            "[Validation Set] Precision: 0.6624\n",
            "[Validation Set] Recall:    0.6500\n",
            "[Validation Set] F1 Score:  0.6561\n",
            "[Validation Set] IoU:       0.4882\n",
            "[Validation Set] Accuracy:  0.8047\n",
            "\n",
            "===== Evaluating Test Set =====\n",
            "[Test Set] Precision: 0.6387\n",
            "[Test Set] Recall:    0.6626\n",
            "[Test Set] F1 Score:  0.6504\n",
            "[Test Set] IoU:       0.4820\n",
            "[Test Set] Accuracy:  0.7944\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6504355463761946, 0.48195965646739264)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Predicting on Harvey image for validation\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "PATCH_SIZE = 128\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Training band stats\n",
        "TRAIN_STATS = {\n",
        "    \"vv\": {\"mean\": 0.4532533777340789, \"std\": 0.151186964809762},\n",
        "    \"vh\": {\"mean\": 0.27253500244271867, \"std\": 0.1730846364169936},\n",
        "}\n",
        "\n",
        "# Normalization (Assumed to be a z-score scaling)\n",
        "def normalize(img, clip_min, clip_max, train_stats):\n",
        "    img_norm = np.zeros_like(img, dtype=np.float32)\n",
        "\n",
        "    for c in range(img.shape[0]):\n",
        "        band = np.clip(img[c], clip_min, clip_max)\n",
        "        mu = np.mean(band)\n",
        "        sigma = np.std(band) + 1e-7\n",
        "\n",
        "        if c == 0:   # VV\n",
        "            target_mu = train_stats[\"vv\"][\"mean\"]\n",
        "            target_sigma = train_stats[\"vv\"][\"std\"]\n",
        "        else:        # VH\n",
        "            target_mu = train_stats[\"vh\"][\"mean\"]\n",
        "            target_sigma = train_stats[\"vh\"][\"std\"]\n",
        "\n",
        "        standardized = (band - mu) / sigma\n",
        "        matched = standardized * target_sigma + target_mu\n",
        "\n",
        "        img_norm[c] = matched\n",
        "\n",
        "        print(f\"[Band {c}] μ_clip={mu:.4f}, σ_clip={sigma:.4f} → μ_target={target_mu:.4f}, σ_target={target_sigma:.4f}\")\n",
        "\n",
        "    return img_norm\n",
        "\n",
        "# Inference\n",
        "def inference(model, img_path):\n",
        "    print(\"FINAL Normalization: Band-wise Clipping & Stat-Matching\")\n",
        "\n",
        "    with rasterio.open(img_path) as src:\n",
        "        image = src.read().astype(np.float32)\n",
        "        image = np.nan_to_num(image, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        h, w = image.shape[1], image.shape[2]\n",
        "\n",
        "    print(\"Applying Band-wise Stats Normalization\")\n",
        "    norm_image = normalize(\n",
        "        image,\n",
        "        CLIP_MIN,\n",
        "        CLIP_MAX,\n",
        "        TRAIN_STATS\n",
        "    )\n",
        "\n",
        "    print(f\"[Check] Final VV Mean = {np.mean(norm_image[0]):.4f}\")\n",
        "    print(f\"[Check] Final VH Mean = {np.mean(norm_image[1]):.4f}\")\n",
        "\n",
        "    pad_h = (PATCH_SIZE - (h % PATCH_SIZE)) % PATCH_SIZE\n",
        "    pad_w = (PATCH_SIZE - (w % PATCH_SIZE)) % PATCH_SIZE\n",
        "    image_padded = np.pad(norm_image, ((0, 0), (0, pad_h), (0, pad_w)), mode='constant')\n",
        "\n",
        "    _, new_h, new_w = image_padded.shape\n",
        "    prediction_map = np.zeros((new_h, new_w), dtype=np.uint8)\n",
        "\n",
        "    model.eval()\n",
        "    print(\"Running Inference...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, new_h, PATCH_SIZE)):\n",
        "            for j in range(0, new_w, PATCH_SIZE):\n",
        "                patch = image_padded[:, i:i+PATCH_SIZE, j:j+PATCH_SIZE]\n",
        "                tensor = torch.from_numpy(patch).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "                output = model(tensor)\n",
        "                prob = torch.sigmoid(output)\n",
        "\n",
        "                pred = (prob > 0.5).cpu().numpy()[0, 0].astype(np.uint8)\n",
        "                prediction_map[i:i+PATCH_SIZE, j:j+PATCH_SIZE] = pred\n",
        "\n",
        "    final_pred = prediction_map[:h, :w]\n",
        "\n",
        "    return final_pred"
      ],
      "metadata": {
        "id": "2ucb9HnkiLQK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "harvey_file = '/content/drive/MyDrive/Colab Notebooks/SARFLOOD/1_gee_sen1_preprocessing/merged_output/S1_VV_2017-08-30_DESCENDING_1_merged.tif'\n",
        "\n",
        "pred = inference(model, harvey_file)"
      ],
      "metadata": {
        "id": "psJgtbihiLSh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "ccdfaf02f32b4d0ebc5332e177ffe8f9",
            "fabcdd2a7ccb447aa17dabf20a22921c",
            "2a0014f60c254faa93256dd78216dc54",
            "9adcd238976448aabb9f457b4670d8a7",
            "4d5217ec51524bf9952ecaa7ff545465",
            "0dd64e46d9414299b1e2f530fca4d482",
            "e0dd8dea8ef44680913d6457debf77ba",
            "98a65b8929ea44deb4559b6064322a1d",
            "ec7fc9c8ec014365a1d59de6fea9e95d",
            "76311412c8b54cd7a15ff5b9743bc0f4",
            "45580601f5b94d729242b83f5f6523a6"
          ]
        },
        "outputId": "9b32e5ca-5d22-4838-af84-aee2b68bc11c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL Normalization: Band-wise Clipping & Stat-Matching\n",
            "Applying Band-wise Stats Normalization\n",
            "[Band 0] μ_clip=-7.8631, σ_clip=5.3288 → μ_target=0.4533, σ_target=0.1512\n",
            "[Band 1] μ_clip=-12.5071, σ_clip=7.9492 → μ_target=0.2725, σ_target=0.1731\n",
            "[Check] Final VV Mean = 0.4532\n",
            "[Check] Final VH Mean = 0.2725\n",
            "Running Inference...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/177 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccdfaf02f32b4d0ebc5332e177ffe8f9"
            }
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ccdfaf02f32b4d0ebc5332e177ffe8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fabcdd2a7ccb447aa17dabf20a22921c",
              "IPY_MODEL_2a0014f60c254faa93256dd78216dc54",
              "IPY_MODEL_9adcd238976448aabb9f457b4670d8a7"
            ],
            "layout": "IPY_MODEL_4d5217ec51524bf9952ecaa7ff545465"
          }
        },
        "fabcdd2a7ccb447aa17dabf20a22921c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dd64e46d9414299b1e2f530fca4d482",
            "placeholder": "​",
            "style": "IPY_MODEL_e0dd8dea8ef44680913d6457debf77ba",
            "value": "100%"
          }
        },
        "2a0014f60c254faa93256dd78216dc54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a65b8929ea44deb4559b6064322a1d",
            "max": 177,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec7fc9c8ec014365a1d59de6fea9e95d",
            "value": 177
          }
        },
        "9adcd238976448aabb9f457b4670d8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76311412c8b54cd7a15ff5b9743bc0f4",
            "placeholder": "​",
            "style": "IPY_MODEL_45580601f5b94d729242b83f5f6523a6",
            "value": " 177/177 [01:26&lt;00:00,  2.05it/s]"
          }
        },
        "4d5217ec51524bf9952ecaa7ff545465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd64e46d9414299b1e2f530fca4d482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0dd8dea8ef44680913d6457debf77ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98a65b8929ea44deb4559b6064322a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec7fc9c8ec014365a1d59de6fea9e95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76311412c8b54cd7a15ff5b9743bc0f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45580601f5b94d729242b83f5f6523a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}